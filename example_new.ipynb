{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8def207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imputation import core_utils, core_imputation_model_new\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d4d0",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d4782",
   "metadata": {},
   "source": [
    "this method loads the data from the corresponding `data_path` this would be the feather file shared on google drive, however it is too large to host on github, it returns the characteristic percentile ranks as a numpy array of shape TxNxC where T is the number of dates N the number of stocks and C the number of characteristics, the raw characteristics, the characteristic namess, the dates, returns and permos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55b9459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd3f42a2ec940cea2985b8d6b335724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/raw_chars_returns_df_yearly_fb_monthly_avg_mergedizes.fthr\"\n",
    "percentile_rank_chars, raw_chars, chars, date_vals, returns, permnos = core_utils.get_data_panel(\n",
    "    path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings = core_utils.CHAR_GROUPINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91f2fc",
   "metadata": {},
   "source": [
    "Two methods we want to highlight are\n",
    "- `core_imputation_model_new.run_imputation`\n",
    "- `core_imputation_model_new.fit_factors_and_loadings`\n",
    "\n",
    "The first runs the full method as described in the paper, including potentially different time series information sets depending on the arguments given.\n",
    "\n",
    "The second generates the factors and loadings. \n",
    "\n",
    "The below examples correspond to global and local fits, the parameters are documented in the function definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efa811",
   "metadata": {},
   "source": [
    "# Running Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13294e59",
   "metadata": {},
   "source": [
    "In this section we will run the imputation method described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6eec50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, N, L = percentile_rank_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7023",
   "metadata": {},
   "source": [
    "## Local Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e2869",
   "metadata": {},
   "source": [
    "We first look at a local estimation, in this case we show how to estimate either the purely cross-sectional model or the cross-sectional model with backwards time series information. \n",
    "\n",
    "Local estimation means we allow the loadings and factors in the cross-sectiona model to vary over time, as well as the time series regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a12d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:   45.7s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f19b79b402840c2a4490f70b02e6d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iteration 0 resids rmse are  0.09356960610594271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:   43.5s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bf830dbe7940ac8996c2790de76ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iteration 1 resids rmse are  0.09247375737291431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:   43.9s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3536107427db41cb951734d7af339b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at iteration 2 resids rmse are  0.09221952242310501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cfdad5947e4ef498fc2f40ab604027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputation = core_imputation_model_new.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01,\n",
    "    use_bw_ts_info=False, \n",
    "    use_fw_ts_info=False,\n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1, \n",
    "    xs_regr_n_iter=3\n",
    ")\n",
    "\n",
    "bw_xs_imputation = core_imputation_model_new.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01,\n",
    "    use_bw_ts_info=True, \n",
    "    use_fw_ts_info=False,\n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1, \n",
    "    xs_regr_n_iter=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_ts, lmbda = core_imputation_model_new.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=min_xs_obs, \n",
    "    K=n_xs_factors, \n",
    "    num_months_train=T,\n",
    "    reg=xs_factor_reg,\n",
    "    time_varying_lambdas=time_varying_loadings,\n",
    "    n_iter=xs_regr_n_iter,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb0e7d",
   "metadata": {},
   "source": [
    "## Gobal Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9a147",
   "metadata": {},
   "source": [
    "We next look at a global estimation, in this case we show how to estimate the global model using forward and backwards time series information as well as the cross-sectional factors. \n",
    "\n",
    "Global estimation means we constrain the loadings in the cross-sectiona model be constant over time, as well as the time series regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = core_imputation_model_new.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01,\n",
    "    use_bw_ts_info=True, \n",
    "    use_fw_ts_info=True,\n",
    "    include_ts_residuals=False,\n",
    "    min_xs_obs=1, \n",
    "    xs_regr_n_iter=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_ts, lmbda = core_imputation_model_new.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=min_xs_obs, \n",
    "    K=n_xs_factors, \n",
    "    num_months_train=T,\n",
    "    reg=xs_factor_reg,\n",
    "    time_varying_lambdas=False,\n",
    "    n_iter=xs_regr_n_iter,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a9582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
