{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8def207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imputation import core_utils, core_imputation_model_new\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d4d0",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d4782",
   "metadata": {},
   "source": [
    "`core_utils.get_data_panel` loads the data from the corresponding `data_path` this would be the feather file shared on google drive, however it is too large to host on github, it returns the characteristic percentile ranks as a numpy array of shape TxNxC where T is the number of dates N the number of stocks and C the number of characteristics, the raw characteristics, the characteristic namess, the dates, returns and permos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55b9459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a854e445b72c461e979a73eb5b672491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/raw_chars_returns_df_yearly_fb_monthly_avg_mergedizes.fthr\"\n",
    "percentile_rank_chars, raw_chars, chars, date_vals, returns, permnos = core_utils.get_data_panel(\n",
    "    path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings = core_utils.CHAR_GROUPINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91f2fc",
   "metadata": {},
   "source": [
    "Two methods we want to highlight are\n",
    "- `core_imputation_model_new.run_imputation`\n",
    "- `core_imputation_model_new.fit_factors_and_loadings`\n",
    "\n",
    "The first runs the full method as described in the paper, including potentially different time series information sets depending on the arguments given.\n",
    "\n",
    "The second generates the factors and loadings. \n",
    "\n",
    "The below examples correspond to global and local fits, the parameters are documented in the function definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efa811",
   "metadata": {},
   "source": [
    "# Running Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa15f6",
   "metadata": {},
   "source": [
    "In this section we will run the imputation method described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3ba60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, N, L = percentile_rank_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7023",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a8e1",
   "metadata": {},
   "source": [
    "We first look at a local estimation, in this case we show how to estimate either the purely cross-sectional model or the cross-sectional model with backwards time series information. \n",
    "\n",
    "We would like to emphasize two parameters in this estimation. This first in the number of cross-sectional factors: `n_xs_factors` the second is the cross-sectional ffactor regularization: `xs_factor_reg`.\n",
    "\n",
    "These two hyperparameters have a significant impact on the performance of the model, and should be chosen carefully. The parameters we use in this example are tuned for the data-set from Missing Financial Data, and should not be considered default aprameters for alternative data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a12d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de640096d0014286a812d6f52abdc19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09351689202831431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a700159458e44d9bb572ebde24e948a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619636e096ac41f99c577696e5a1892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09351689202831431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e070e133f4bd986d06dfb5c992297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8054b8db1240d3910e91467a49a7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2970bb11f14b87a32e13d615dfc594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputation = core_imputation_model_new.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.00022,\n",
    "    use_bw_ts_info=False, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")\n",
    "\n",
    "bw_xs_imputation = core_imputation_model_new.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.00022,\n",
    "    use_bw_ts_info=True, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "290ddd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=30)]: Done 228 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=30)]: Done 528 out of 528 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241b545e7e4d43238f0ee9e1d3b17885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09351689202831431\n"
     ]
    }
   ],
   "source": [
    "gamma_ts, lmbda = core_imputation_model_new.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=1, \n",
    "    K=20, \n",
    "    num_months_train=T,\n",
    "    reg=0.00022,\n",
    "    time_varying_lambdas=True,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a516f99",
   "metadata": {},
   "source": [
    "# On Hyperparameter Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83080899",
   "metadata": {},
   "source": [
    "Below we show the plots from figure 8 in the paper. This are the kinds of plot we used to determine the optional regularization and number of factors. Namely, we considered the out of sample performance of the model implied by a certain hyperparater choice across a grid of thsese choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c00c26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data/example_of_cval.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"data/example_of_cval.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7b05d",
   "metadata": {},
   "source": [
    "The `core_imputation_model_new.fit_factors_and_loadings` method allows the use to pass in and argument `eval_data`. This, if provided, is compared against the imputation and the RMSE is reported. This is simple way that hyperparameter choices could be evaluated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71bb842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data/reg_cval.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"data/reg_cval.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667115aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
