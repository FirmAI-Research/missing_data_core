{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8def207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imputation import core_utils, core_imputation_model\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d4d0",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d4782",
   "metadata": {},
   "source": [
    "`core_utils.get_data_panel` loads the data from the corresponding `data_path` this would be the feather file shared on google drive, however it is too large to host on github, it returns the characteristic percentile ranks as a numpy array of shape TxNxC where T is the number of dates N the number of stocks and C the number of characteristics, the raw characteristics, the characteristic namess, the dates, returns and permos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55b9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/example_data.fthr\"\n",
    "percentile_rank_chars, chars, date_vals, returns, permnos = core_utils.get_data_panel(\n",
    "    path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings = core_utils.CHAR_GROUPINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efa811",
   "metadata": {},
   "source": [
    "# Running Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa15f6",
   "metadata": {},
   "source": [
    "In this section we will run the imputation method described in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36889c6",
   "metadata": {},
   "source": [
    "Two methods we want to highlight are\n",
    "- `core_imputation_model_new.run_imputation`\n",
    "- `core_imputation_model_new.fit_factors_and_loadings`\n",
    "\n",
    "The first runs the full method as described in the paper, including potentially different time series information sets depending on the arguments given.\n",
    "\n",
    "The second generates the factors and loadings. \n",
    "\n",
    "The below examples correspond to global and local fits, the parameters are documented in the function definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3ba60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, N, L = percentile_rank_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7023",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a8e1",
   "metadata": {},
   "source": [
    "We first look at a local estimation, in this case we show how to estimate either the purely cross-sectional model or the cross-sectional model with backwards time series information. \n",
    "\n",
    "We would like to emphasize two parameters in this estimation. This first in the number of cross-sectional factors: `n_xs_factors` the second is the cross-sectional ffactor regularization: `xs_factor_reg`.\n",
    "\n",
    "These two hyperparameters have a significant impact on the performance of the model, and should be chosen carefully. The parameters we use in this example are tuned for the data-set from Missing Financial Data, and should not be considered default aprameters for alternative data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a12d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    7.9s remaining:   15.8s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.0s remaining:    5.7s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    8.4s remaining:    1.7s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f6bc5818cc4b3699c7621cadf60243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d769e04d5d7b424c9ccd4277cec19468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    8.5s remaining:   17.0s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.7s remaining:    6.2s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    8.8s remaining:    1.8s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c0632a3cc64ede8ba40735ddfa2ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c235471831704260b51012c28703178f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e695cda7542c4dc3aceb8af108f783dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b64c678931b4f078ae2d231bd88ec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T, N, L = percentile_rank_chars.shape\n",
    "\n",
    "imputation = core_imputation_model.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01 / L,\n",
    "    use_bw_ts_info=False, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")\n",
    "\n",
    "bw_xs_imputation = core_imputation_model.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01 / L,\n",
    "    use_bw_ts_info=True, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290ddd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    8.2s remaining:   16.5s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.6s remaining:    6.1s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    8.8s remaining:    1.8s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d7995b9f0947d8bfc7841dcd24902b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.0951762749598058\n"
     ]
    }
   ],
   "source": [
    "gamma_ts, lmbda = core_imputation_model.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=1, \n",
    "    K=20, \n",
    "    num_months_train=T,\n",
    "    reg=0.00022,\n",
    "    time_varying_lambdas=True,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a516f99",
   "metadata": {},
   "source": [
    "# On Hyperparameter Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83080899",
   "metadata": {},
   "source": [
    "Below we show the plots from figures 8 \\& 9 in the paper. This are the kinds of plots we used to determine the optional regularization and number of factors. Namely, we considered the out of sample performance of the model implied by a certain hyperparameter choice across a grid of thsese choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5051b0",
   "metadata": {},
   "source": [
    "![data/reg_cval.png](data/example_of_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1e86b",
   "metadata": {},
   "source": [
    "![data/reg_cval.png](data/reg_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd093a",
   "metadata": {},
   "source": [
    "The `core_imputation_model_new.fit_factors_and_loadings` method allows the use to pass in and argument `eval_data`. This, if provided, is compared against the imputation and the RMSE is reported. This is simple way that hyperparameter choices could be evaluated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5616d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
