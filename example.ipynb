{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8def207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imputation import core_utils, core_imputation_model\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d4d0",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d4782",
   "metadata": {},
   "source": [
    "`core_utils.get_data_panel` loads the data from the corresponding `data_path`, which is a feather file shared on Google drive. We have to use Gdrive as it is too large to host on Github. The data file it contains the characteristic percentile ranks as a numpy array of shape TxNxL where T is the number of dates, N the number of stocks, and L the number of characteristics. The file also includes the raw characteristics, the characteristic namess, the dates and permnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55b9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/example_data.fthr\"\n",
    "percentile_rank_chars, chars, date_vals, permnos = core_utils.get_data_panel(\n",
    "    path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings = core_utils.CHAR_GROUPINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efa811",
   "metadata": {},
   "source": [
    "# Running Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa15f6",
   "metadata": {},
   "source": [
    "In this section we will run the imputation method described in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36889c6",
   "metadata": {},
   "source": [
    "Two methods we want to highlight are\n",
    "- `core_imputation_model_new.run_imputation`\n",
    "- `core_imputation_model_new.fit_factors_and_loadings`\n",
    "\n",
    "The first code runs the full method as described in the paper, including potentially different time series information sets depending on the arguments given.\n",
    "\n",
    "The second code estimates the XS factor model. \n",
    "\n",
    "The examples below correspond to global and local fits. The parameters are documented in the function definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3ba60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T, N, L = percentile_rank_chars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7023",
   "metadata": {},
   "source": [
    "## Estimating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a8e1",
   "metadata": {},
   "source": [
    "We start with the local estimation. In this case, we show how to estimate either the purely cross-sectional model (local XS) or the cross-sectional model with backwards time series information (local B-XS). \n",
    "\n",
    "We would like to emphasize two parameters in this estimation. This first is the number of cross-sectional factors K: `n_xs_factors` the second is the cross-sectional factor regularization gamma: `xs_factor_reg`.\n",
    "\n",
    "These two hyperparameters have a significant impact on the performance of the model, and should be selected carefully. The parameters we use in this example are selected for the data-set from Missing Financial Data, and should not be considered default aprameters for alternative data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a12d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    8.7s remaining:   17.4s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.9s remaining:    6.4s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    9.2s remaining:    1.8s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993559d348934e6284a2d45691213081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109d85f5238a458fb256e9b06bf09aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    8.6s remaining:   17.2s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.9s remaining:    6.3s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    9.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6936d3da6074971945ba304277d465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a0dd9c01694f4ba5e2de7c6d679d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c2aa348ab346ddb5eb55565796de08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4401ec15ac4789a33569a5d46d3fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T, N, L = percentile_rank_chars.shape\n",
    "\n",
    "imputation = core_imputation_model.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01 / L,\n",
    "    use_bw_ts_info=False, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")\n",
    "\n",
    "bw_xs_imputation = core_imputation_model.run_imputation(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01 / L,\n",
    "    use_bw_ts_info=True, \n",
    "    include_ts_residuals=True,\n",
    "    min_xs_obs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290ddd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    8.5s remaining:   17.1s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    8.9s remaining:    6.4s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    9.6s remaining:    1.9s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728b138cff9d4768a0e38608301b7f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.0951762749598058\n"
     ]
    }
   ],
   "source": [
    "gamma_ts, lmbda = core_imputation_model.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=1, \n",
    "    K=20, \n",
    "    num_months_train=T,\n",
    "    reg=0.01 / L,\n",
    "    time_varying_lambdas=True,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a516f99",
   "metadata": {},
   "source": [
    "# On the Selction of the Number of Factors and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83080899",
   "metadata": {},
   "source": [
    "Below we show the plots from Figures 8 \\& 9 in the paper. These figures illustrate how to determine the optimal regularization and number of factors. In more detail, we evaluate the out-of-sample performance of the model for different number of factors and regularization across a grid of these choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5051b0",
   "metadata": {},
   "source": [
    "![example_of_cval.png](example_of_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1e86b",
   "metadata": {},
   "source": [
    "![reg_cval.png](reg_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd093a",
   "metadata": {},
   "source": [
    "The `core_imputation_model_new.fit_factors_and_loadings` method allows the use to pass in and argument `eval_data`. This, if provided, is compared against the imputation and the RMSE is reported. This is simple way that hyperparameter choices could be evaluated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5616d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
